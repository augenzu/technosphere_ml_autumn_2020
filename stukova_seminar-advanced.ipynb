{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Быстро строим деревья"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Деревья глубины 1 обычно называют решающими пнями. \n",
    "Как Вы думаете, какая сложность построения решающего пня?\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Представим, что мы решаем задачу регрессии, считаем для одного сплита. \n",
    "\n",
    "$$Q = F(R_m) - \\frac{N_l}{N_m} F(R_l) - \\frac{N_r}{N_m} F(R_r) $$\n",
    "\n",
    "$$F(R) = \\frac{1}{N} \\sum_{i=1}^{N}(mean(y) - y_i) ^ 2 $$\n",
    "\n",
    "$$Q = F(R_m) - \\frac{1}{N_m} [ \\sum_{i \\in R_l}(mean(y_l) - y_i) ^ 2  +  \\sum_{i \\in R_r}(mean(y_r) - y_i) ^ 2 ]  $$\n",
    "\n",
    "$F(R_m) и N_m$ от сплита не зависит, можно отбросить. Осталось научиться быстро считать такие выражения:\n",
    "$\\sum_{i \\in R_l}(mean(y_l) - y_i) ^ 2$ для всех порогов. \n",
    "\n",
    "Если делать в лоб, то получится $O(||R||^2)$, нам не нравится, очень долго. Каждый раз пересчитывать довольно глупо, потому что мы точно знаем, какой именно объект при изменении сплита перешел из левой части в правую!\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Воспользуемся формулой для дисперсии:\n",
    "$$D(R) = mean(y ^ 2) -  mean(y) ^ 2 =   \\frac{1}{N} \\sum_{i \\in R} y_i^2 -  \\frac{1}{N ^ 2} (\\sum_{i \\in R} y_i) ^2$$\n",
    "\n",
    "Но у нас не дисперсия, а дисперсия без деления на число объектов, то есть:\n",
    "$$\\sum_{i \\in R_l}(mean(y_l) - y_i) ^ 2 =   \\sum_{i \\in R_k} y_i^2 -  \\frac{1}{N_l} (\\sum_{i \\in R_l} y_i) ^2 $$\n",
    "Аналогично для правого сплита. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вот мы и получили более простой алгоритм подсчета сплита:\n",
    "\n",
    "1) Отсортировали фичу и таргет по фиче\n",
    "\n",
    "2) Сначала считаем, что порог это минимальное значение, то есть левый кусок пустой, правый все значения. Храним для каждой из частей\n",
    "а) Сумму\n",
    "б) Сумму квадратов\n",
    "в) Число объектов\n",
    "\n",
    "3) Взяли следующее значение в отсортированном списке, это значение ушло от правого куска в левое. Обновили а) б) в) в обоих кусках\n",
    "\n",
    "4) Посчитали  для каждого куска б) - а) ** 2 / в), сложили для обоих кусков. Если эта сумма маеньше лучшего значения, то это лучший сплит из текущих\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте алгоритм, сравните качество со sklearn.\n",
    "\n",
    "Если получилось одинаково, Вы молодец!!!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_threshold(feature, y):\n",
    "    best_thr = None\n",
    "    idxs = sorted(range(len(feature)),key=feature.__getitem__)\n",
    "    left_sum = 0\n",
    "    right_sum = sum(y)\n",
    "    left_sq_sum = 0\n",
    "    right_sq_sum = sum([elm ** 2 for elm in y])\n",
    "    left_n = 0\n",
    "    right_n = len(y)\n",
    "    best_err = right_sq_sum - (right_sum ** 2) / right_n\n",
    "    for idx in idxs:\n",
    "        elm = y[idx]\n",
    "        left_sum += elm\n",
    "        right_sum -= elm\n",
    "        left_sq_sum += (elm ** 2)\n",
    "        right_sq_sum -= (elm ** 2)\n",
    "        left_n += 1\n",
    "        right_n -= 1\n",
    "        left_err = left_sq_sum - (left_sum ** 2) / left_n\n",
    "        right_err = right_sq_sum - (right_sum ** 2) / right_n\n",
    "        err = left_err + right_err\n",
    "        if err < best_err:\n",
    "            best_err = err\n",
    "            best_thr = feature[idx]\n",
    "    return best_err, best_thr\n",
    "\n",
    "\n",
    "def train_stump(X, y):\n",
    "    best_f = None\n",
    "    best_thr = None\n",
    "    best_error = float('inf')\n",
    "    left_mean, right_mean = None, None\n",
    "    for j in range(len(X[0])):\n",
    "        f_error, f_thr = get_threshold(X[:][j], y)\n",
    "        if f_error < best_error:\n",
    "            best_error = f_error\n",
    "            best_f = j\n",
    "            best_thr = f_thr\n",
    "    lefts = [y[i] for i in range(len(y)) if X[i][best_f] <= best_thr]\n",
    "    rights = [y[i] for i in range(len(y)) if X[i][best_f] > best_thr]\n",
    "    left_mean = 0 if lefts == [] else sum(lefts) / len(lefts)\n",
    "    right_mean = 0 if rights == [] else sum(rights) / len(rights)\n",
    "    return best_f, best_thr, left_mean, right_mean\n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MyDecisionTreeRegressor:\n",
    "    def fit(self, X, y):\n",
    "        self.best_f, self.best_thr, \\\n",
    "                self.left_mean, self.right_mean = train_stump(X, y)\n",
    "        return self\n",
    "        \n",
    "        \n",
    "    def predict(self, X):\n",
    "        y_pred = [\n",
    "            self.left_mean if X[i][self.best_f] <= self.best_thr\n",
    "            else self.right_mean\n",
    "            for i in range(len(X))\n",
    "        ]\n",
    "        return y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_boston\n",
    "X, y = load_boston(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.0\n",
      "46.19909167710848\n"
     ]
    }
   ],
   "source": [
    "from sklearn.tree import DecisionTreeRegressor\n",
    "from sklearn.metrics import mean_squared_error\n",
    "regressor = DecisionTreeRegressor(random_state=0).fit(X, y)\n",
    "print(mean_squared_error(y, regressor.predict(X)))\n",
    "regressor_stump = DecisionTreeRegressor(random_state=0, max_depth=1).fit(X, y)\n",
    "print(mean_squared_error(y, regressor_stump.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "84.41955615616554\n"
     ]
    }
   ],
   "source": [
    "my_regressor = MyDecisionTreeRegressor().fit(X, y)\n",
    "print(mean_squared_error(y, my_regressor.predict(X)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
